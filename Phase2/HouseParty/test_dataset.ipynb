{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image, ImageEnhance\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx = 17\n",
    "cy = 41\n",
    "cw = 367\n",
    "ch = 471\n",
    "dataroot = '/opt/ml/input/purified'\n",
    "\n",
    "class MaskDataset(Dataset):\n",
    "    # dataroot = '/opt/ml/input/purified'\n",
    "    def __init__(self, dataroot: str, isTrain: bool, n_class=18):\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        self.isTrain = isTrain\n",
    "        self.transform = T.Compose([\n",
    "                            T.RandomRotation((0,15)),\n",
    "                            T.Resize((64, 64)),\n",
    "                            T.RandomAutocontrast(0.3),\n",
    "                            T.RandomHorizontalFlip(0.5),\n",
    "                            T.ToTensor(),\n",
    "                        ])\n",
    "\n",
    "        if isTrain:\n",
    "            dataroot = os.path.join(dataroot, 'train')\n",
    "            cls0 = [0,1,2,3,4,5]\n",
    "            cls1 = [6,7,8,9,10,11]\n",
    "            cls2 = [12,13,14,15,16,17]\n",
    "            if (len(cls0 + cls1 + cls2) != n_class) or (len(set(cls0+cls1+cls2)) != n_class):\n",
    "                raise Exception('[MaskDataset Exeption]: Need mental caring')\n",
    "\n",
    "            for cls in range(n_class):\n",
    "                if cls in cls0:     m_cls = 0\n",
    "                elif cls in cls1:   m_cls = 1\n",
    "                elif cls in cls2:   m_cls = 2\n",
    "                else:\n",
    "                    raise Exception('[Dataset Exeption]: check rootdir')\n",
    "\n",
    "                cls_paths = glob(f'{dataroot}/{cls}/*.*')\n",
    "                self.x.extend( cls_paths )\n",
    "                self.y.extend( [m_cls] * len(cls_paths) )\n",
    "        \n",
    "        else:\n",
    "            dataroot = os.path.join(dataroot, 'test')\n",
    "            self.x = glob(f'{dataroot}/' + '*.*')\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = Image.open(self.x[idx])\n",
    "        X = self._preprocess(X)\n",
    "\n",
    "        if self.isTrain:\n",
    "            if self.transform:    \n",
    "                X = self.transform(X)\n",
    "            return X, self.y[idx]\n",
    "        else:               \n",
    "            return X\n",
    "\n",
    "    def _preprocess(self, X: str)->Image:\n",
    "        X = X.crop((cx,cy,cw,ch))\n",
    "        X = ImageEnhance.Contrast(X).enhance(5)\n",
    "        X = ImageEnhance.Color(X).enhance(0.8)\n",
    "        return X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python385jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}