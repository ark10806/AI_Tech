{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "base = '/opt/ml/input/data/train/'\n",
    "csv_path = os.path.join(base, 'train.csv')\n",
    "img_path = os.path.join(base, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18900\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "base = '/opt/ml/input/data/train/images/'\n",
    "jpg = glob.glob(base + '**/*.jpg', recursive=True)\n",
    "png = glob.glob(base + '**/*.png', recursive=True)\n",
    "jpeg = glob.glob(base + '**/*.jpeg', recursive=True)\n",
    "\n",
    "print(len(jpg) + len(png) + len(jpeg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001108', 'female', 'Asian', '23']\n",
      "['001108', 'female', 'Asian', '23']\n",
      "['001108', 'female', 'Asian', '23']\n",
      "['001108', 'female', 'Asian', '23']\n",
      "['001108', 'female', 'Asian', '23']\n",
      "['001108', 'female', 'Asian', '23']\n",
      "['001108', 'female', 'Asian', '23']\n",
      "['001817', 'male', 'Asian', '23']\n",
      "['001817', 'male', 'Asian', '23']\n",
      "['001817', 'male', 'Asian', '23']\n",
      "['001817', 'male', 'Asian', '23']\n",
      "['001817', 'male', 'Asian', '23']\n"
     ]
    }
   ],
   "source": [
    "src = base = '/opt/ml/input/data/train/images/'\n",
    "\n",
    "for idx, img in enumerate(glob.glob(src + '**/*.*', recursive=True)):\n",
    "    dir_name, ext = os.path.splitext(img)\n",
    "    is_masked = dir_name.split('/')[-1]\n",
    "    etc = dir_name.split('/')[-2].split('_')\n",
    "    features = [is_masked[0], etc[1], int(etc[3])]\n",
    "    print(etc)\n",
    "\n",
    "    if idx > 10 : break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12600\n"
     ]
    }
   ],
   "source": [
    "base = '/opt/ml/input/'\n",
    "src = os.path.join(base, 'data/eval')\n",
    "\n",
    "tot = len(glob.glob(src + '/images/' + '**/*.*', recursive=True))\n",
    "# for idx, img in enumerate(glob.glob(src + '/images/' + '**/*.*', recursive=True)):\n",
    "#     dir_name, ext = os.path.splitext(img)\n",
    "#     # print(f'{dir_name.split(\"/\")[-1]}.{ext}')\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "18900"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "\n",
    "all_img = glob.glob(src + '**/*.*', recursive=True)\n",
    "\n",
    "print(type(all_img[0]))\n",
    "img = Image.open(all_img[0])\n",
    "# imshow(np.asarray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "\n",
    "def get_transforms_img(im):\n",
    "    # im = torchvision.transforms.Resize((224,224))(im)\n",
    "    # im = torchvision.transforms.RandomHorizontalFlip()(im)\n",
    "    # im = torchvision.transforms.CenterCrop((150,150))(im)\n",
    "\n",
    "    im = transforms.Compose([\n",
    "                        transforms.CenterCrop((300,300)),\n",
    "                        transforms.Resize((32,32)),\n",
    "                        # transforms.RandomHorizontalFlip(),\n",
    "    ])(im)\n",
    "    \n",
    "    return im\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 384])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7fd6779b0dc0>"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i += 1\n",
    "img = read_image(all_img[i])\n",
    "print(img.shape)\n",
    "img = get_transforms_img(img)\n",
    "imshow(np.asarray(img).transpose((1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>gender</th>\n      <th>race</th>\n      <th>age</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000001</td>\n      <td>female</td>\n      <td>Asian</td>\n      <td>45</td>\n      <td>000001_female_Asian_45</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000002</td>\n      <td>female</td>\n      <td>Asian</td>\n      <td>52</td>\n      <td>000002_female_Asian_52</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000004</td>\n      <td>male</td>\n      <td>Asian</td>\n      <td>54</td>\n      <td>000004_male_Asian_54</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000005</td>\n      <td>female</td>\n      <td>Asian</td>\n      <td>58</td>\n      <td>000005_female_Asian_58</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>000006</td>\n      <td>female</td>\n      <td>Asian</td>\n      <td>59</td>\n      <td>000006_female_Asian_59</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2695</th>\n      <td>006954</td>\n      <td>male</td>\n      <td>Asian</td>\n      <td>19</td>\n      <td>006954_male_Asian_19</td>\n    </tr>\n    <tr>\n      <th>2696</th>\n      <td>006955</td>\n      <td>male</td>\n      <td>Asian</td>\n      <td>19</td>\n      <td>006955_male_Asian_19</td>\n    </tr>\n    <tr>\n      <th>2697</th>\n      <td>006956</td>\n      <td>male</td>\n      <td>Asian</td>\n      <td>19</td>\n      <td>006956_male_Asian_19</td>\n    </tr>\n    <tr>\n      <th>2698</th>\n      <td>006957</td>\n      <td>male</td>\n      <td>Asian</td>\n      <td>20</td>\n      <td>006957_male_Asian_20</td>\n    </tr>\n    <tr>\n      <th>2699</th>\n      <td>006959</td>\n      <td>male</td>\n      <td>Asian</td>\n      <td>19</td>\n      <td>006959_male_Asian_19</td>\n    </tr>\n  </tbody>\n</table>\n<p>2700 rows × 5 columns</p>\n</div>",
      "text/plain": "          id  gender   race  age                    path\n0     000001  female  Asian   45  000001_female_Asian_45\n1     000002  female  Asian   52  000002_female_Asian_52\n2     000004    male  Asian   54    000004_male_Asian_54\n3     000005  female  Asian   58  000005_female_Asian_58\n4     000006  female  Asian   59  000006_female_Asian_59\n...      ...     ...    ...  ...                     ...\n2695  006954    male  Asian   19    006954_male_Asian_19\n2696  006955    male  Asian   19    006955_male_Asian_19\n2697  006956    male  Asian   19    006956_male_Asian_19\n2698  006957    male  Asian   20    006957_male_Asian_20\n2699  006959    male  Asian   19    006959_male_Asian_19\n\n[2700 rows x 5 columns]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(csv_path)\n",
    "dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dir = os.listdir(img_path)\n",
    "real_dir = []\n",
    "for d in list_dir:\n",
    "    if d.find('._')==-1:\n",
    "        real_dir.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000001</td>\n      <td>female</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000002</td>\n      <td>female</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000004</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000005</td>\n      <td>female</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>000006</td>\n      <td>female</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2695</th>\n      <td>006954</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>2696</th>\n      <td>006955</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>2697</th>\n      <td>006956</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>2698</th>\n      <td>006957</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>2699</th>\n      <td>006959</td>\n      <td>male</td>\n    </tr>\n  </tbody>\n</table>\n<p>2700 rows × 2 columns</p>\n</div>",
      "text/plain": "          id  gender\n0     000001  female\n1     000002  female\n2     000004    male\n3     000005  female\n4     000006  female\n...      ...     ...\n2695  006954    male\n2696  006955    male\n2697  006956    male\n2698  006957    male\n2699  006959    male\n\n[2700 rows x 2 columns]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[['id', 'gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"000600-1\" at position 207",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to parse string \"000600-1\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d70e73952ae3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/tools/numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[0;34m(arg, errors, downcast)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mcoerce_numeric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             values = lib.maybe_convert_numeric(\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             )\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to parse string \"000600-1\" at position 207"
     ]
    }
   ],
   "source": [
    "len(real_dir)\n",
    "pd.to_numeric(dataframe['id']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-32a4dee8dfc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.tensor(dataframe['id'].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python385jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}